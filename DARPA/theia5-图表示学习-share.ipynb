{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成每天的测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load(\"./models/model_saved_emb100_BATCH_1024_LastAggregator_multiclass.pt\")\n",
    "memory,gnn, link_pred,neighbor_loader=model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_5_8=test_day_new(graph_5_8,\"graph_5_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ans_5_9=test_day_new(graph_5_9,\"graph_5_9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_5_11=test_day_new(graph_5_11,\"graph_5_11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_5_14=test_day_new(graph_5_14,\"graph_5_14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_5_15=test_day_new(graph_5_15,\"graph_5_15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算IDF字典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这部分的代码使用jinyuan 优化过后的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 5-9的IDF值\n",
    "\n",
    "# share_node_IDF = mp.Manager().dict()\n",
    "\n",
    "node_set=set()\n",
    "\n",
    "file_list=[]\n",
    "\n",
    "file_path=\"graph_5_9/\"\n",
    "file_l=os.listdir(\"graph_5_9/\")\n",
    "for i in file_l:\n",
    "    file_list.append(file_path+i)\n",
    "\n",
    "# file_path=\"graph_4_5/\"\n",
    "# file_l=os.listdir(\"graph_4_5/\")\n",
    "# for i in file_l:\n",
    "#     file_list.append(file_path+i)\n",
    "\n",
    "# file_path=\"graph_4_6/\"\n",
    "# file_l=os.listdir(\"graph_4_6/\")\n",
    "# for i in file_l:\n",
    "#     file_list.append(file_path+i)\n",
    "\n",
    "\n",
    "# file_path=\"graph_4_7/\"\n",
    "# file_l=os.listdir(\"graph_4_7/\")\n",
    "# for i in file_l:\n",
    "#     file_list.append(file_path+i)\n",
    "\n",
    "for f_path in tqdm(file_list):\n",
    "    f=open(f_path)\n",
    "    for line in f:\n",
    "        l=line.strip()\n",
    "        jdata=eval(l)\n",
    "        if jdata['loss']>0:\n",
    "            if 'netflow' not in str(jdata['srcmsg']):\n",
    "                node_set.add(str(jdata['srcmsg']))\n",
    "            if 'netflow' not in str(jdata['dstmsg']):\n",
    "                node_set.add(str(jdata['dstmsg'])) \n",
    "\n",
    "\n",
    "node_list=list(node_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 窗口关系建立函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_include_key_word(s):\n",
    "    keywords=[\n",
    "         'netflow',\n",
    "        '/dev/pts',\n",
    "         'proc',\n",
    "      ]\n",
    "    flag=False\n",
    "    for i in keywords:\n",
    "        if i in s:\n",
    "            flag=True\n",
    "    return flag\n",
    "\n",
    "\n",
    "def cal_set_rel(s1,s2,file_list):\n",
    "    new_s=s1 & s2\n",
    "    count=0\n",
    "    for i in new_s:\n",
    "\n",
    "        if is_include_key_word(i) is not True:\n",
    "\n",
    "            if i in node_IDF.keys():\n",
    "                IDF=node_IDF[i]\n",
    "            else:\n",
    "                IDF=math.log(len(file_list)/(1))\n",
    "\n",
    "            if (IDF)>4.5 :\n",
    "                print(\"node:\",i,\" IDF:\",IDF)\n",
    "                count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 异常检测5-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-14 直接计算窗口的异常分数\n",
    "\n",
    "node_IDF=torch.load(\"node_IDF_5_9\")\n",
    "y_data_5_14=[]\n",
    "df_list_5_14=[]\n",
    "# node_set_list=[]\n",
    "history_list_5_14=[]\n",
    "tw_que=[]\n",
    "his_tw={}\n",
    "current_tw={}\n",
    "loss_list_5_14=[]\n",
    "\n",
    "\n",
    "file_path_list=[]\n",
    "file_path=\"graph_5_14/\"\n",
    "file_l=os.listdir(\"graph_5_14/\")\n",
    "for i in file_l:\n",
    "    file_path_list.append(file_path+i)\n",
    "    \n",
    "    \n",
    "index_count=0\n",
    "for f_path in (file_path_list):\n",
    "    f=open(f_path)\n",
    "    edge_loss_list=[]\n",
    "    edge_list=[]\n",
    "    print('index_count:',index_count)\n",
    "    \n",
    "    for line in f:\n",
    "        l=line.strip()\n",
    "        jdata=eval(l)\n",
    "        edge_loss_list.append(jdata['loss'])\n",
    "        edge_list.append([str(jdata['srcmsg']),str(jdata['dstmsg'])])\n",
    "    df_list_5_14.append(pd.DataFrame(edge_loss_list))\n",
    "    count,loss_avg,node_set,edge_set=cal_anomaly_loss(edge_loss_list,edge_list,\"graph_5_14/\")\n",
    "    # 为当前窗口提取相关信息 用于和历史窗口进行对比\n",
    "    current_tw['name']=f_path\n",
    "    current_tw['loss']=loss_avg\n",
    "    current_tw['index']=index_count\n",
    "    current_tw['nodeset']=node_set\n",
    "\n",
    "    added_que_flag=False\n",
    "    for hq in history_list_5_14:\n",
    "        for his_tw in hq:\n",
    "#             if False: # 默认每个窗口之间没联系\n",
    "            if cal_set_rel(current_tw['nodeset'],his_tw['nodeset'],file_list_5_9)!=0 and current_tw['name']!=his_tw['name']:\n",
    "                print(\"history queue:\",his_tw['name'])\n",
    "                # 判断两个窗口之间是否存在交集\n",
    "                hq.append(copy.deepcopy(current_tw))\n",
    "                added_que_flag=True\n",
    "                break\n",
    "            if added_que_flag:\n",
    "                break\n",
    "    if added_que_flag is False:\n",
    "        temp_hq=[copy.deepcopy(current_tw)]\n",
    "        history_list_5_14.append(temp_hq)\n",
    "    index_count+=1\n",
    "    loss_list_5_14.append(loss_avg)\n",
    "    print( f_path,\"  \",loss_avg,\" count:\",count,\" percentage:\",count/len(edge_list),\" node count:\",len(node_set),\" edge count:\",len(edge_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list=[]\n",
    "for hl in history_list_5_14:\n",
    "    loss_count=0\n",
    "    for hq in hl:\n",
    "        if loss_count==0:\n",
    "            loss_count=(loss_count+1)*(hq['loss']+1)\n",
    "        else:\n",
    "            loss_count=(loss_count)*(hq['loss']+1)\n",
    "#     name_list=[]\n",
    "    if loss_count>7:\n",
    "        name_list=[]\n",
    "        for i in hl:\n",
    "            name_list.append(i['name']) \n",
    "        print(name_list)\n",
    "        for i in name_list:\n",
    "            pred_label[i]=1\n",
    "        print(loss_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 异常检测5-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-15 直接计算窗口的异常分数\n",
    "\n",
    "# node_IDF=torch.load(\"node_IDF_5_15\")\n",
    "node_IDF=torch.load(\"node_IDF_5_9\")\n",
    "y_data_5_15=[]\n",
    "df_list_5_15=[]\n",
    "# node_set_list=[]\n",
    "history_list_5_15=[]\n",
    "tw_que=[]\n",
    "his_tw={}\n",
    "current_tw={}\n",
    "loss_list_5_15=[]\n",
    "\n",
    "\n",
    "\n",
    "file_path_list=[]\n",
    "file_path=\"graph_5_15/\"\n",
    "file_l=os.listdir(\"graph_5_15/\")\n",
    "for i in file_l:\n",
    "    file_path_list.append(file_path+i)\n",
    "\n",
    "index_count=0\n",
    "for f_path in (file_path_list):\n",
    "    f=open(f_path)\n",
    "    edge_loss_list=[]\n",
    "    edge_list=[]\n",
    "    print('index_count:',index_count)\n",
    "    \n",
    "    for line in f:\n",
    "        l=line.strip()\n",
    "        jdata=eval(l)\n",
    "        edge_loss_list.append(jdata['loss'])\n",
    "        edge_list.append([str(jdata['srcmsg']),str(jdata['dstmsg'])])\n",
    "    df_list_5_15.append(pd.DataFrame(edge_loss_list))\n",
    "    count,loss_avg,node_set,edge_set=cal_anomaly_loss(edge_loss_list,edge_list,\"graph_5_15/\")\n",
    "    # 为当前窗口提取相关信息 用于和历史窗口进行对比\n",
    "    current_tw['name']=f_path\n",
    "    current_tw['loss']=loss_avg\n",
    "    current_tw['index']=index_count\n",
    "    current_tw['nodeset']=node_set\n",
    "\n",
    "    added_que_flag=False\n",
    "    for hq in history_list_5_15:\n",
    "        for his_tw in hq:\n",
    "#             if False: # 默认每个窗口之间没联系\n",
    "            if cal_set_rel(current_tw['nodeset'],his_tw['nodeset'],file_list_5_9)!=0 and current_tw['name']!=his_tw['name']:\n",
    "                print(\"history queue:\",his_tw['name'])\n",
    "                # 判断两个窗口之间是否存在交集\n",
    "                hq.append(copy.deepcopy(current_tw))\n",
    "                added_que_flag=True\n",
    "                break\n",
    "            if added_que_flag:\n",
    "                break\n",
    "    if added_que_flag is False:\n",
    "        temp_hq=[copy.deepcopy(current_tw)]\n",
    "        history_list_5_15.append(temp_hq)\n",
    "    index_count+=1\n",
    "    loss_list_5_15.append(loss_avg)\n",
    "    print( f_path,\"  \",loss_avg,\" count:\",count,\" percentage:\",count/len(edge_list),\" node count:\",len(node_set),\" edge count:\",len(edge_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list=[]\n",
    "for hl in history_list_5_15:\n",
    "    loss_count=0\n",
    "    for hq in hl:\n",
    "        if loss_count==0:\n",
    "            loss_count=(loss_count+1)*(hq['loss']+1)\n",
    "        else:\n",
    "            loss_count=(loss_count)*(hq['loss']+1)\n",
    "#     name_list=[]\n",
    "    if loss_count>7:\n",
    "        name_list=[]\n",
    "        for i in hl:\n",
    "            name_list.append(i['name']) \n",
    "        print(name_list)\n",
    "        for i in name_list:\n",
    "            pred_label[i]=1\n",
    "        print(loss_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={}\n",
    "pred_label={}    \n",
    "    \n",
    "filelist = os.listdir(\"graph_5_14\")\n",
    "for f in filelist:\n",
    "    labels[\"graph_5_14/\"+f]=0\n",
    "    pred_label[\"graph_5_14/\"+f]=0\n",
    "\n",
    "filelist = os.listdir(\"graph_5_15\")\n",
    "for f in filelist:\n",
    "    labels[\"graph_5_15/\"+f]=0\n",
    "    pred_label[\"graph_5_15/\"+f]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_list=[\n",
    "    'graph_5_15/2019-05-15 13:58:15.520482252~2019-05-15 14:13:37.257086895.txt',\n",
    "    'graph_5_15/2019-05-15 14:44:51.773840192~2019-05-15 15:00:26.765466538.txt',\n",
    "]\n",
    "#  theia -1  的攻击场景\n",
    "for i in attack_list:\n",
    "    labels[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计attack edge数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_hit(line):\n",
    "    attack_nodes=[\n",
    "#             'sshd',\n",
    "            'sshdlog',\n",
    "        'shm',\n",
    "#          'python',\n",
    "#             'firefox',\n",
    "        '189.141.204.211',\n",
    "        '208.203.20.42',\n",
    "       \n",
    "#         '',\n",
    "#         '',\n",
    "#         '',\n",
    "        ]\n",
    "    flag=False\n",
    "    for i in attack_nodes:\n",
    "        if i in line:\n",
    "            flag=True\n",
    "            break\n",
    "    return flag\n",
    "\n",
    "\n",
    "\n",
    "files=[    \n",
    "    'graph_5_15/2019-05-15 13:58:15.520482252~2019-05-15 14:13:37.257086895.txt',\n",
    "    'graph_5_15/2019-05-15 14:44:51.773840192~2019-05-15 15:00:26.765466538.txt',]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_edge_count=0\n",
    "for fpath in tqdm(files):\n",
    "    f=open(fpath)\n",
    "    for line in f:\n",
    "        if keyword_hit(line):\n",
    "            attack_edge_count+=1\n",
    "print(attack_edge_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化分析模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dic={\n",
    "    '/run/shm/':'/run/shm/*',\n",
    "#     '/home/admin/.cache/mozilla/firefox/pe11scpa.default/cache2/entries/':'/home/admin/.cache/mozilla/firefox/pe11scpa.default/cache2/entries/*',\n",
    "   '/home/admin/.cache/mozilla/firefox/':'/home/admin/.cache/mozilla/firefox/*',\n",
    "    '/home/admin/.mozilla/firefox':'/home/admin/.mozilla/firefox*',    \n",
    "    '/data/replay_logdb/':'/data/replay_logdb/*', \n",
    "    '/home/admin/.local/share/applications/':'/home/admin/.local/share/applications/*', \n",
    "    '/usr/share/applications/':'/usr/share/applications/*', \n",
    "    '/lib/x86_64-linux-gnu/':'/lib/x86_64-linux-gnu/*',     \n",
    "    '/proc/':'/proc/*', \n",
    "     '/stat':'*/stat', \n",
    "    '/etc/bash_completion.d/':'/etc/bash_completion.d/*', \n",
    "    '/usr/bin/python2.7':'/usr/bin/python2.7/*', \n",
    "     '/usr/lib/python2.7':'/usr/lib/python2.7/*', \n",
    "'/data/data/org.mozilla.fennec_firefox_dev/cache/':'/data/data/org.mozilla.fennec_firefox_dev/cache/*',\n",
    "    'UNNAMED':'UNNAMED*',\n",
    "    '/etc/fonts/':'/etc/fonts/*',\n",
    "}\n",
    "\n",
    "def replace_path_name(path_name):\n",
    "    for i in replace_dic:\n",
    "        if i in path_name:\n",
    "            return replace_dic[i]\n",
    "    return path_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_edges_count=0\n",
    "hash2msg={}\n",
    "graphs=[]\n",
    "gg=nx.DiGraph()\n",
    "count=0\n",
    "# file_list=os.listdir(\"./test_day_data4_10_emb100/\")\n",
    "for path in tqdm(attack_list):\n",
    "#     print(path)\n",
    "    if \".txt\" in path:\n",
    "        line_count=0\n",
    "        node_set=set()\n",
    "        tempg=nx.DiGraph()\n",
    "        f=open(path,\"r\")       \n",
    "        edge_list=[]\n",
    "        for line in f:\n",
    "            count+=1\n",
    "            l=line.strip()\n",
    "            jdata=eval(l)\n",
    "#             temp_key=jdata['srcmsg']+jdata['dstmsg']+jdata['edge_type']\n",
    "#             if temp_key in train_edge_set:\n",
    "#                 jdata['loss']=(jdata['loss']-train_edge_set[temp_key]) if jdata['loss']>=train_edge_set[temp_key] else 0  \n",
    "#             jdata['loss']=abs(jdata['loss']-train_edge_set[temp_key])  if temp_key in train_edge_set else jdata['loss']\n",
    "            edge_list.append(jdata)\n",
    "            \n",
    "        edge_list = sorted(edge_list, key=lambda x:x['loss'],reverse=True) \n",
    "        original_edges_count+=len(edge_list)\n",
    "        \n",
    "        loss_list=[]\n",
    "        for i in edge_list:\n",
    "            loss_list.append(i['loss'])\n",
    "        loss_mean=mean(loss_list)\n",
    "        loss_std=std(loss_list)\n",
    "        print(loss_mean)\n",
    "        print(loss_std)\n",
    "        thr=loss_mean+1.5*loss_std\n",
    "#         thr=-99\n",
    "        print(\"thr:\",thr)\n",
    "        for e in edge_list:\n",
    "            if e['loss']>thr:    \n",
    "#             if True:  \n",
    "#                 if \"'/home/admin/profile'\" in e['srcmsg'] or \" '/home/admin/profile'\" in e['dstmsg']:\n",
    "#                     print(e['srcmsg'])\n",
    "#                     print(e['dstmsg'])\n",
    "                tempg.add_edge(str(hashgen(replace_path_name(e['srcmsg']))),str(hashgen(replace_path_name(e['dstmsg']))))\n",
    "                gg.add_edge(str(hashgen(replace_path_name(e['srcmsg']))),str(hashgen(replace_path_name(e['dstmsg']))),loss=e['loss'],srcmsg=e['srcmsg'],dstmsg=e['dstmsg'],edge_type=e['edge_type'],time=e['time'])\n",
    "                \n",
    "                hash2msg[str(hashgen(replace_path_name(e['srcmsg'])))]=replace_path_name(e['srcmsg'])\n",
    "                hash2msg[str(hashgen(replace_path_name(e['dstmsg'])))]=replace_path_name(e['dstmsg'])\n",
    "                \n",
    "            #不去除重复节点\n",
    "#                 gg.add_edge(e['srcnode'],e['dstnode'],loss=e['loss'],srcmsg=e['srcmsg'],dstmsg=e['dstmsg'],edge_type=e['edge_type'],time=e['time'])\n",
    "        print(path)\n",
    "        print(\"tempg edges:\",len(tempg.edges))\n",
    "        print(\"tempg nodes:\",len(tempg.nodes))\n",
    "        print(\"tempg weakly components:\",nx.number_weakly_connected_components(tempg))\n",
    "        \n",
    "        print(\"gg edges:\",len(gg.edges))\n",
    "        print(\"gg nodes:\",len(gg.nodes))\n",
    "        print(\"gg weakly components:\",nx.number_weakly_connected_components(gg))\n",
    "        print(f\"{original_edges_count=}\")\n",
    "#                                 不去除重复节点\n",
    "#                 gg.add_edge(e['srcnode'],e['dstnode'],loss=e['loss'],srcmsg=e['srcmsg'],dstmsg=e['dstmsg'],edge_type=e['edge_type'],time=e['time'])\n",
    "#         print(path,\" line_count:\",line_count,\"  nodes count:\",len(node_set))\n",
    "#         print(path,\" line_count:\",line_count,\"  nodes count:\",len(node_set))\n",
    "                \n",
    "                \n",
    "                #         graphs.append(g)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里没有加入太多染色节点，后期手动对比GT文档\n",
    "\n",
    "def attack_edge_flag(msg):\n",
    "    attack_edge_type=[        \n",
    "        '208.203.20.42',\n",
    "        '189.141.204.211',\n",
    "        '/var/log/sshdlog',\n",
    "        '/usr/sbin/sshd',\n",
    "        '/usr/local/lib/firefox-54.0.1/firefox',        \n",
    "  \n",
    "    ]\n",
    "    flag=False\n",
    "    for i in attack_edge_type:\n",
    "        if i in msg:\n",
    "            flag=True\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 异常检测结果统计分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "沿用其他数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyg20]",
   "language": "python",
   "name": "conda-env-pyg20-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "225.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
